{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.]])\n",
      "tensor([[ 4.,  3.,  2.,  1.],\n",
      "        [ 9.,  8.,  7.,  6.],\n",
      "        [14., 13., 12., 11.]])\n",
      "tensor([[4, 3, 2, 1],\n",
      "        [4, 3, 2, 1],\n",
      "        [4, 3, 2, 1]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# a = torch.arange(15).reshape(3, 5).float()\n",
    "# print(a)\n",
    "# vals, inds = a.topk(k=4, dim=-1)\n",
    "# print(vals)\n",
    "# print(inds)\n",
    "# print(vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --fuzzy \"https://drive.google.com/file/d/12ycYSzLIG253AFN35Y6qoyf9wtkOjakp/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -zxvf \"./2017-01-trnmted.tgz\"\n",
    "# !tar -zxvf \"./2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo.tgz\"\n",
    "# !mv ./DeEnItNlRo-DeEnItNlRo ./texts\n",
    "# !mkdir ./clean_texts\n",
    "# !mkdir ./tokenizers\n",
    "# !rm \"./2017-01-trnmted.tgz\"\n",
    "# !rm -rf \"./2017-01-trnmted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "from pathlib import Path\n",
    "\n",
    "# data.convert_files(Path('./texts'), Path('./clean_texts'))\n",
    "# data.train_tokenizers(Path('./clean_texts'), Path('./tokenizers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import train_model, train_epoch, translate_test_set\n",
    "\n",
    "# train_model(\"./clean_texts\", \"./tokenizers\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from sacrebleu.metrics import BLEU\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "from data import TranslationDataset\n",
    "from decoding import translate, get_attn_mask\n",
    "from model import TranslationModel\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./clean_texts\")\n",
    "tokenizer_path = Path(\"./tokenizers\")\n",
    "src_tokenizer = Tokenizer.from_file(str(tokenizer_path / \"tokenizer_de.json\"))\n",
    "tgt_tokenizer = Tokenizer.from_file(str(tokenizer_path / \"tokenizer_en.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\" : 6,\n",
    "    \"lr\" : 3e-4,\n",
    "    \"max_len\" : 128,  # might be enough at first\n",
    "    \"num_encoder_layers\" : 3,\n",
    "    \"num_decoder_layers\" : 3,\n",
    "    \"emb_size\" : 256,\n",
    "    \"dim_feedforward\" : 512,\n",
    "    \"n_head\" : 8,\n",
    "    \"dropout_prob\" : 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "# train_dataset = TranslationDataset(\n",
    "#     data_dir / \"train.de.txt\",\n",
    "#     data_dir / \"train.en.txt\",\n",
    "#     src_tokenizer,\n",
    "#     tgt_tokenizer,\n",
    "#     max_len=128 #config[\"max_len\"],\n",
    "# )\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=6,\n",
    "#     collate_fn = train_dataset.collate_translation_data,\n",
    "#     # shuffle=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TranslationDataset(\n",
    "    data_dir / \"val.de.txt\",\n",
    "    data_dir / \"val.en.txt\",\n",
    "    src_tokenizer,\n",
    "    tgt_tokenizer,\n",
    "    max_len=config[\"max_len\"],\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    config[\"batch_size\"],\n",
    "    collate_fn = val_dataset.collate_translation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of model parameters: pytorch_total_params = 27024688\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "src_pad_id = tgt_tokenizer.token_to_id(\"[PAD]\")\n",
    "tgt_pad_id = tgt_tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "model = TranslationModel(\n",
    "    config[\"num_encoder_layers\"],\n",
    "    config[\"num_decoder_layers\"],\n",
    "    config[\"emb_size\"],\n",
    "    config[\"dim_feedforward\"],\n",
    "    config[\"n_head\"],\n",
    "    src_tokenizer.get_vocab_size(),\n",
    "    tgt_tokenizer.get_vocab_size(),\n",
    "    config[\"dropout_prob\"],\n",
    "    src_pad_id,\n",
    "    tgt_pad_id,\n",
    "    config[\"max_len\"]\n",
    ")\n",
    "\n",
    "# model.load_state_dict(torch.load(\"checkpoint_last.pth\")[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "print(\"Total no. of model parameters:\",\n",
    "    \"pytorch_total_params =\", sum(p.numel() for p in model.parameters())\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"saved.pth\")[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_model import train_epoch, evaluate, translate_test_set\n",
    "\n",
    "# num_epochs=1\n",
    "# optimizer = torch.optim.Adam(model.parameters(), config[\"lr\"])\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer,\n",
    "#     config[\"lr\"],\n",
    "#     steps_per_epoch=len(train_dataloader),\n",
    "#     epochs=num_epochs,\n",
    "#     pct_start=0.1\n",
    "# )\n",
    "# CELoss = torch.nn.CrossEntropyLoss(ignore_index=tgt_pad_id)\n",
    "\n",
    "# min_val_loss = float(\"inf\")\n",
    "\n",
    "# for epoch in trange(1, num_epochs + 1):\n",
    "#     val_loss = evaluate(model, train_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_model import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdlishudi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dima/DL/LHW2/DL-LHW1/wandb/run-20221206_041409-3vdqueyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dlishudi/DL-LHW2/runs/3vdqueyd\" target=\"_blank\">lilac-water-17</a></strong> to <a href=\"https://wandb.ai/dlishudi/DL-LHW2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dlishudi/DL-LHW2/runs/3vdqueyd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7efcb6c4b670>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# wandb.init(config=config, project=\"DL-LHW2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c2e313390146049974394df5e266ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.475229707924095\n"
     ]
    }
   ],
   "source": [
    "# for epoch in trange(1):\n",
    "#     val_loss, table = evaluate(model, val_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer, wandb)\n",
    "#     print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"examples\" : table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"epoch\" : epoch,\n",
    "    \"val_loss\" : val_loss,\n",
    "    \"first batch translation\" : table\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff402c9af8744f3db476300aca5b10b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.012 MB of 0.017 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.741443…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lilac-water-17</strong>: <a href=\"https://wandb.ai/dlishudi/DL-LHW2/runs/3vdqueyd\" target=\"_blank\">https://wandb.ai/dlishudi/DL-LHW2/runs/3vdqueyd</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221206_041409-3vdqueyd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [45, 46, 47, 48, 49]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10* 5).reshape(10,5)\n",
    "mask = torch.tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1]).bool()\n",
    "a[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_485/2840094636.py\", line 1, in <module>\n",
      "    translate_test_set(model, data_dir, tokenizer_path, batch_size=8)\n",
      "  File \"/home/dima/DL/LHW2/DL-LHW1/train_model.py\", line 275, in translate_test_set\n",
      "    greed_out = translate(model, src_sentences, src_tokenizer, tgt_tokenizer, \"greedy\", device)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dima/DL/LHW2/DL-LHW1/decoding.py\", line 199, in translate\n",
      "  File \"/home/dima/DL/LHW2/DL-LHW1/decoding.py\", line 62, in _greedy_decode\n",
      "    new_tokens = model.decode_last(\n",
      "  File \"/home/dima/DL/LHW2/DL-LHW1/model.py\", line 120, in decode_last\n",
      "    decoded = self.transformer.decoder(\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 333, in forward\n",
      "    output = mod(output, memory, tgt_mask=tgt_mask,\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 648, in forward\n",
      "    x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 669, in _mha_block\n",
      "    x = self.multihead_attn(x, mem, mem,\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 1167, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/torch/nn/functional.py\", line 5069, in multi_head_attention_forward\n",
      "    raise RuntimeError(f\"The shape of the 2D attn_mask is {attn_mask.shape}, but should be {correct_2d_size}.\")\n",
      "RuntimeError: The shape of the 2D attn_mask is torch.Size([8, 55]), but should be (1, 55).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/dima/.local/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "translate_test_set(model, data_dir, tokenizer_path, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([1, 2, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([1, 4, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([1, 5, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([6, 6])\n",
      "torch.Size([1, 6, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 7])\n",
      "torch.Size([7, 7])\n",
      "torch.Size([1, 7, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([1, 8, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([1, 9, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([1, 10, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 11])\n",
      "torch.Size([11, 11])\n",
      "torch.Size([1, 11, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([12, 12])\n",
      "torch.Size([1, 12, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 13])\n",
      "torch.Size([13, 13])\n",
      "torch.Size([1, 13, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([1, 14, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 15])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([1, 15, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([1, 16, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([17, 17])\n",
      "torch.Size([1, 17, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 18])\n",
      "torch.Size([18, 18])\n",
      "torch.Size([1, 18, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 19])\n",
      "torch.Size([19, 19])\n",
      "torch.Size([1, 19, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([1, 20, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 21])\n",
      "torch.Size([21, 21])\n",
      "torch.Size([1, 21, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 22])\n",
      "torch.Size([22, 22])\n",
      "torch.Size([1, 22, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 23])\n",
      "torch.Size([23, 23])\n",
      "torch.Size([1, 23, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 24])\n",
      "torch.Size([24, 24])\n",
      "torch.Size([1, 24, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 25])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([1, 25, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 26])\n",
      "torch.Size([26, 26])\n",
      "torch.Size([1, 26, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([1, 2, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([1, 4, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([1, 5, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([6, 6])\n",
      "torch.Size([1, 6, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 7])\n",
      "torch.Size([7, 7])\n",
      "torch.Size([1, 7, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([1, 8, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([1, 9, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([1, 10, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 11])\n",
      "torch.Size([11, 11])\n",
      "torch.Size([1, 11, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([12, 12])\n",
      "torch.Size([1, 12, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 13])\n",
      "torch.Size([13, 13])\n",
      "torch.Size([1, 13, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([1, 14, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 15])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([1, 15, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([1, 16, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([17, 17])\n",
      "torch.Size([1, 17, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 18])\n",
      "torch.Size([18, 18])\n",
      "torch.Size([1, 18, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 19])\n",
      "torch.Size([19, 19])\n",
      "torch.Size([1, 19, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([1, 20, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 21])\n",
      "torch.Size([21, 21])\n",
      "torch.Size([1, 21, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 22])\n",
      "torch.Size([22, 22])\n",
      "torch.Size([1, 22, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 23])\n",
      "torch.Size([23, 23])\n",
      "torch.Size([1, 23, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 24])\n",
      "torch.Size([24, 24])\n",
      "torch.Size([1, 24, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 25])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([1, 25, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 26])\n",
      "torch.Size([26, 26])\n",
      "torch.Size([1, 26, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([27, 27])\n",
      "torch.Size([1, 27, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 28])\n",
      "torch.Size([28, 28])\n",
      "torch.Size([1, 28, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 29])\n",
      "torch.Size([29, 29])\n",
      "torch.Size([1, 29, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 30])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([1, 30, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 31])\n",
      "torch.Size([31, 31])\n",
      "torch.Size([1, 31, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([1, 32, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 33])\n",
      "torch.Size([33, 33])\n",
      "torch.Size([1, 33, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 34])\n",
      "torch.Size([34, 34])\n",
      "torch.Size([1, 34, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 35])\n",
      "torch.Size([35, 35])\n",
      "torch.Size([1, 35, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 36])\n",
      "torch.Size([36, 36])\n",
      "torch.Size([1, 36, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 37])\n",
      "torch.Size([37, 37])\n",
      "torch.Size([1, 37, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 38])\n",
      "torch.Size([38, 38])\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 39])\n",
      "torch.Size([39, 39])\n",
      "torch.Size([1, 39, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 40])\n",
      "torch.Size([40, 40])\n",
      "torch.Size([1, 40, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 41])\n",
      "torch.Size([41, 41])\n",
      "torch.Size([1, 41, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 42])\n",
      "torch.Size([42, 42])\n",
      "torch.Size([1, 42, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 38, 256])\n",
      "torch.Size([1, 43])\n",
      "torch.Size([43, 43])\n",
      "torch.Size([1, 43, 256])\n",
      "torch.Size([1, 30000])\n",
      "--------------------------------------------------\n",
      "BLEU with greedy search: 12.653180025616605, with beam search: 0\n"
     ]
    }
   ],
   "source": [
    "translate_test_set(model, data_dir, tokenizer_path, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacremoses import MosesDetokenizer, MosesPunctNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src_tokenizer.token_to_id(\"[PAD]\")\n",
    "tgt_tokenizer.token_to_id(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W', 'hat', 'are', 'you', 'do', 'ing', '?']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS]', 'Hi', 'Mad', 'ina', '[EOS]']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hi Madina\"\n",
    "src_tokenizer.encode(text).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "src_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[EOS] $A [BOS]\",\n",
    "    pair=\"[EOS] $A [UNK] $B:1 [BOS]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[EOS]\", src_tokenizer.token_to_id(\"[EOS]\")),\n",
    "        (\"[BOS]\", src_tokenizer.token_to_id(\"[BOS]\")),\n",
    "        (\"[UNK]\", src_tokenizer.token_to_id(\"[UNK]\"))\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encs = tgt_tokenizer.encode_batch([\"Hello, Marina\", \"Hi Dima!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[BOS]', 'Hello', ',', 'Mar', 'ina', '[EOS]']\n",
      "['[BOS]', 'Hi', 'D', 'ima', '!', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "for i in batch_encs:\n",
    "    print(i.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tgt_tokenizer.decode_batch(torch.Tensor(batch_ids).long().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's fine!\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacremoses import MosesPunctNormalizer\n",
    "mpn = MosesPunctNormalizer()\n",
    "\"It ' s fine!\".replace(\" '\", \"'\").replace(\"' \", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detok.deto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hell o , World !\n",
      "Hell o, World!\n",
      "Hell o , World !\n"
     ]
    }
   ],
   "source": [
    "from sacremoses import MosesDetokenizer, MosesPunctNormalizer\n",
    "\n",
    "detok = MosesDetokenizer()\n",
    "mpn = MosesPunctNormalizer()\n",
    "\n",
    "text = \"Hello, World!\"\n",
    "encoded = src_tokenizer.encode(text).ids\n",
    "decoded = src_tokenizer.decode(encoded)\n",
    "detokenized = detok.detokenize(decoded.split())\n",
    "normalized = mpn.normalize(decoded)\n",
    "print(decoded)\n",
    "print(detokenized)\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W hat are you do ing? W hat are you do ing?'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubled = [decoded, decoded]\n",
    "detok.detokenize(doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ich erzähle Ihnen mal eine Geschichte , dann verstehen Sie mich vielleicht besser .', 'Eine wahre Geschichte -- kein Wort daran ist erfunden .']\n",
      "Ich erzähle Ihnen mal eine Geschichte, dann verstehen Sie mich vielleicht besser. Eine wahre Geschichte -- kein Wort daran ist erfunden.\n",
      "['Ich erzähle Ihnen mal eine Geschichte , dann verstehen Sie mich vielleicht besser .', 'Eine wahre Geschichte -- kein Wort daran ist erfunden .']\n"
     ]
    }
   ],
   "source": [
    "seqs = src_tokenizer.decode_batch([train_dataset[7][0].tolist(), train_dataset[8][0].tolist()])\n",
    "# seqs = \"WHAT , ARE YOU ' LL DOING ?\"\n",
    "print(seqs)\n",
    "print(MosesDetokenizer().detokenize(seqs))\n",
    "print(MosesPunctNormalizer().normalize(seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Ich erzähle Ihnen mal eine Geschichte , dann verstehen Sie mich vielleicht besser .', 'Eine wahre Geschichte -- kein Wort daran ist erfunden .']\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MosesPunctNormalizer().normalize(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m seqs[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seqs' is not defined"
     ]
    }
   ],
   "source": [
    "seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db85bd5464b4942a8a8a5be908fcab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f51ecbe85504c5db218263ae6a3ae72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m min_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, train_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/DL/LHW2/DL-LHW1/train_model.py:117\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, val_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer, logger)\u001b[0m\n\u001b[1;32m    114\u001b[0m     loss \u001b[39m=\u001b[39m CELoss(out, tgt[:,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    116\u001b[0m     \u001b[39m# loss calc\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m bs\n\u001b[1;32m    118\u001b[0m     total_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bs\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m total_size\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,   698,   175,   215,   467,    15,  2040,    17,     3,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   194,   159,    10,    82,  2691,    64,   589,  4596,   155,\n",
      "           223,   147,  1869,   155,   451,   155,   197,  1899,  3318,    30,\n",
      "            42,    10,    76,  2433,  5685,    17,     3,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,   223,   426,  7699,   880,   325,   197,  3479,    15,\n",
      "           163,    42,   358,   155,  2075,   209,   162,   175,   199,   147,\n",
      "           516,  1936,  7305,   255,   246,    42,   336,   155,   399,   147,\n",
      "           333,  1227,    17,     3],\n",
      "        [    2,   194,    42,   399,   168,  1428,  4112,    15,  6879,   341,\n",
      "            42,   442,   168,    17,     3,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,  6704,  7990,   146,   274,  2036,    17,     3,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,  5322,   152,  5157,  8729,  3021,   199,  1731,   408,\n",
      "            17,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   415,    42,   223,   155,   521,   550,   274,  4339,   160,\n",
      "          9146,   155,   309,   152,   148,  4319,     4,     3,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,    10,   185,   517,   175,   225,  1394,   743,   155,\n",
      "          8506,   246,   168,    10,    82,   426,   280,   199,   188,    17,\n",
      "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   282,    10,    82,    64,  1303,   743,   233,   395,   606,\n",
      "           162,   197,   154,  1303,    17,     3,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2, 12171,   669, 22319,   163,    42,  1000,   147,   233,  5858,\n",
      "          5670,   233,   174,   344,  2868,   294,   235,   913,   146, 18983,\n",
      "           155,    64,   478,  4202,   174,   223,   928,  2054,  6174,   162,\n",
      "         18983,    17,     3,     1],\n",
      "        [    2, 15208,   490,  1463,    17,     3,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,   304,   159,  2313,   280,    64,   478,   236,   155,\n",
      "           175,    15,   295,   233,    42,  1264,   146,   147, 10794,    16,\n",
      "          1010,  4817,   163,   209,   162,    64,  1955,   159,   307,  2295,\n",
      "           188,    17,     3,     1],\n",
      "        [    2,   530,   210,   305,  3864, 22336,   448,   275,    17,     3,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   374,    10,   176,  1290,   162,  7937,  6042,  1196,    32,\n",
      "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   383,   210,    64, 14147,  7762,    53, 26683,    17,     3,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   282,   210,  4183,   370,    15,   163,   174,   706,   815,\n",
      "           199,    64,   708,   155,  1792,    17,     3,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    for line in i[\"tgt\"]:\n",
    "        print(line)\n",
    "    print(i[\"tgt\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dl2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d0befdef6903fb005fd1e5f215c1a662f048223f39c989b40eaab18772d8785"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
