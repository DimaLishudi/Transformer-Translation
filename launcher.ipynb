{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --fuzzy \"https://drive.google.com/file/d/12ycYSzLIG253AFN35Y6qoyf9wtkOjakp/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -zxvf \"./2017-01-trnmted.tgz\"\n",
    "# !tar -zxvf \"./2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo.tgz\"\n",
    "# !mv ./DeEnItNlRo-DeEnItNlRo ./texts\n",
    "# !mkdir ./clean_texts\n",
    "# !mkdir ./tokenizers\n",
    "# !rm \"./2017-01-trnmted.tgz\"\n",
    "# !rm -rf \"./2017-01-trnmted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "# from pathlib import Path\n",
    "\n",
    "# data.convert_files(Path('./texts'), Path('./clean_texts'))\n",
    "# data.train_tokenizers(Path('./clean_texts'), Path('./tokenizers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import train_model, train_epoch\n",
    "\n",
    "# train_model(\"./clean_texts\", \"./tokenizers\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from sacrebleu.metrics import BLEU\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "from data import TranslationDataset\n",
    "from decoding import translate, get_attn_mask\n",
    "from model import TranslationModel\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./clean_texts\")\n",
    "tokenizer_path = Path(\"./tokenizers\")\n",
    "src_tokenizer = Tokenizer.from_file(str(tokenizer_path / \"tokenizer_de.json\"))\n",
    "tgt_tokenizer = Tokenizer.from_file(str(tokenizer_path / \"tokenizer_en.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\" : 12,\n",
    "    \"lr\" : 3e-4,\n",
    "    \"max_len\" : 128,  # might be enough at first\n",
    "    \"num_encoder_layers\" : 1,\n",
    "    \"num_decoder_layers\" : 1,\n",
    "    \"emb_size\" : 256,\n",
    "    \"dim_feedforward\" : 1024,\n",
    "    \"n_head\" : 8,\n",
    "    \"dropout_prob\" : 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "train_dataset = TranslationDataset(\n",
    "    data_dir / \"train.de.txt\",\n",
    "    data_dir / \"train.en.txt\",\n",
    "    src_tokenizer,\n",
    "    tgt_tokenizer,\n",
    "    max_len=128 #config[\"max_len\"],\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn = train_dataset.collate_translation_data,\n",
    "    # shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   2,  269, 4900,  500,  427,  214,  774,   15,  419,  998,  231,  405,\n",
       "          726,  695,   17,    3]),\n",
       " tensor([   2,   42,   10,  185,  517,  175,  225, 1394,  743,  155, 8506,  246,\n",
       "          168,   10,   82,  426,  280,  199,  188,   17,    3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12882"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of model parameters: pytorch_total_params = 24914224\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "src_pad_id = tgt_tokenizer.token_to_id(\"[PAD]\")\n",
    "tgt_pad_id = tgt_tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "model = TranslationModel(\n",
    "    config[\"num_encoder_layers\"],\n",
    "    config[\"num_decoder_layers\"],\n",
    "    config[\"emb_size\"],\n",
    "    config[\"dim_feedforward\"],\n",
    "    config[\"n_head\"],\n",
    "    src_tokenizer.get_vocab_size(),\n",
    "    tgt_tokenizer.get_vocab_size(),\n",
    "    config[\"dropout_prob\"],\n",
    "    src_pad_id,\n",
    "    tgt_pad_id,\n",
    "    config[\"max_len\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Total no. of model parameters:\",\n",
    "    \"pytorch_total_params =\", sum(p.numel() for p in model.parameters())\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db85bd5464b4942a8a8a5be908fcab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f51ecbe85504c5db218263ae6a3ae72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m min_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, train_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/DL/LHW2/DL-LHW1/train_model.py:117\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, val_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer, logger)\u001b[0m\n\u001b[1;32m    114\u001b[0m     loss \u001b[39m=\u001b[39m CELoss(out, tgt[:,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    116\u001b[0m     \u001b[39m# loss calc\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m bs\n\u001b[1;32m    118\u001b[0m     total_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bs\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m total_size\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train_model import train_epoch, evaluate\n",
    "\n",
    "num_epochs=1\n",
    "optimizer = torch.optim.Adam(model.parameters(), config[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    config[\"lr\"],\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    epochs=num_epochs,\n",
    "    pct_start=0.1\n",
    ")\n",
    "CELoss = torch.nn.CrossEntropyLoss(ignore_index=tgt_pad_id)\n",
    "\n",
    "min_val_loss = float(\"inf\")\n",
    "\n",
    "# for epoch in trange(1, num_epochs + 1):\n",
    "#     val_loss = evaluate(model, train_dataloader, CELoss, device, src_tokenizer, tgt_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,   698,   175,   215,   467,    15,  2040,    17,     3,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   194,   159,    10,    82,  2691,    64,   589,  4596,   155,\n",
      "           223,   147,  1869,   155,   451,   155,   197,  1899,  3318,    30,\n",
      "            42,    10,    76,  2433,  5685,    17,     3,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,   223,   426,  7699,   880,   325,   197,  3479,    15,\n",
      "           163,    42,   358,   155,  2075,   209,   162,   175,   199,   147,\n",
      "           516,  1936,  7305,   255,   246,    42,   336,   155,   399,   147,\n",
      "           333,  1227,    17,     3],\n",
      "        [    2,   194,    42,   399,   168,  1428,  4112,    15,  6879,   341,\n",
      "            42,   442,   168,    17,     3,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,  6704,  7990,   146,   274,  2036,    17,     3,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,  5322,   152,  5157,  8729,  3021,   199,  1731,   408,\n",
      "            17,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   415,    42,   223,   155,   521,   550,   274,  4339,   160,\n",
      "          9146,   155,   309,   152,   148,  4319,     4,     3,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,    10,   185,   517,   175,   225,  1394,   743,   155,\n",
      "          8506,   246,   168,    10,    82,   426,   280,   199,   188,    17,\n",
      "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   282,    10,    82,    64,  1303,   743,   233,   395,   606,\n",
      "           162,   197,   154,  1303,    17,     3,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2, 12171,   669, 22319,   163,    42,  1000,   147,   233,  5858,\n",
      "          5670,   233,   174,   344,  2868,   294,   235,   913,   146, 18983,\n",
      "           155,    64,   478,  4202,   174,   223,   928,  2054,  6174,   162,\n",
      "         18983,    17,     3,     1],\n",
      "        [    2, 15208,   490,  1463,    17,     3,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,    42,   304,   159,  2313,   280,    64,   478,   236,   155,\n",
      "           175,    15,   295,   233,    42,  1264,   146,   147, 10794,    16,\n",
      "          1010,  4817,   163,   209,   162,    64,  1955,   159,   307,  2295,\n",
      "           188,    17,     3,     1],\n",
      "        [    2,   530,   210,   305,  3864, 22336,   448,   275,    17,     3,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   374,    10,   176,  1290,   162,  7937,  6042,  1196,    32,\n",
      "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   383,   210,    64, 14147,  7762,    53, 26683,    17,     3,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    2,   282,   210,  4183,   370,    15,   163,   174,   706,   815,\n",
      "           199,    64,   708,   155,  1792,    17,     3,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    for line in i[\"tgt\"]:\n",
    "        print(line)\n",
    "    print(i[\"tgt\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dl2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d0befdef6903fb005fd1e5f215c1a662f048223f39c989b40eaab18772d8785"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
